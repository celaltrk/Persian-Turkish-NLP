{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-LpNwXd-ciSr",
    "outputId": "ca1c90ca-01a3-4320-8702-2e35cf78fdd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in ./.venv/lib/python3.12/site-packages (4.3.3)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: optuna in ./.venv/lib/python3.12/site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in ./.venv/lib/python3.12/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in ./.venv/lib/python3.12/site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in ./.venv/lib/python3.12/site-packages (from optuna) (1.15.2)\n",
      "Requirement already satisfied: colorlog in ./.venv/lib/python3.12/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in ./.venv/lib/python3.12/site-packages (from optuna) (2.0.41)\n",
      "Requirement already satisfied: PyYAML in ./.venv/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in ./.venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in ./.venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in ./.venv/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim tqdm optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "L2qo-5I-Yutg",
    "outputId": "b05e09fa-3bd5-42a8-98d8-411a134b9182"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 20:55:43,764 : INFO : Number of workers is 13\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from gensim.models import FastText\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "DATA_DIR = Path(\"./preprocessed\")\n",
    "MODEL_OUTPUT_DIR = Path(\"./embedding_models\")\n",
    "MODEL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# FastText Model Parameters\n",
    "VECTOR_SIZE = 100  # Dimensionality of the word vectors\n",
    "WINDOW_SIZE = 5    # Context window size\n",
    "MIN_WORD_COUNT = 5 # Minimum word frequency to consider\n",
    "SKIP_GRAM = 1      # 1 for Skip-gram, 0 for CBOW. Skip-gram is generally better.\n",
    "EPOCHS = 15        # Number of training iterations over the corpus\n",
    "MIN_N_CHAR_GRAM = 3 # Minimum length of char n-grams\n",
    "MAX_N_CHAR_GRAM = 6 # Maximum length of char n-grams\n",
    "NEGATIVE = 5 # SGNS\n",
    "\n",
    "NUM_WORKERS = os.cpu_count() if os.cpu_count() else 4 # Use available CPU cores\n",
    "NUM_WORKERS = NUM_WORKERS - 3 # prevent excessive load\n",
    "logging.info(f\"Number of workers is {NUM_WORKERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8ivg6ZhMe0ZY"
   },
   "outputs": [],
   "source": [
    "def train_decade_model(text_file_path):\n",
    "    decade_name = text_file_path.name[-9:-4]  # 1930s, 1940s, etc\n",
    "    logging.info(f\"--- Processing decade: {decade_name} ---\")\n",
    "\n",
    "    preprocessed_file_path = DATA_DIR / f\"preprocessed_{decade_name}.txt\"\n",
    "    logging.info(f\"Loading preprocessed sentences from {preprocessed_file_path}...\")\n",
    "    try:\n",
    "        with open(preprocessed_file_path, 'r', encoding='utf-8') as f:\n",
    "            sentences = [line.strip().split() for line in f.readlines()]\n",
    "        logging.info(f\"Loaded {len(sentences)} sentences from preprocessed file.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Could not read preprocessed file {preprocessed_file_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Train the FastText model\n",
    "    logging.info(f\"Training FastText model for {decade_name}...\")\n",
    "    model = FastText(\n",
    "        sentences=sentences,\n",
    "        vector_size=VECTOR_SIZE,\n",
    "        window=WINDOW_SIZE,\n",
    "        min_count=MIN_WORD_COUNT,\n",
    "        sg=SKIP_GRAM,\n",
    "        negative=NEGATIVE,\n",
    "        epochs=EPOCHS,\n",
    "        min_n=MIN_N_CHAR_GRAM,\n",
    "        max_n=MAX_N_CHAR_GRAM,\n",
    "        workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    # Save the trained model\n",
    "    model_save_path = MODEL_OUTPUT_DIR / f\"fasttext_{decade_name}.model\"\n",
    "    try:\n",
    "        model.save(str(model_save_path))\n",
    "        logging.info(f\"Model for {decade_name} saved to {model_save_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Could not save model for {decade_name}: {e}\")\n",
    "\n",
    "    logging.info(f\"--- Finished processing for decade: {decade_name} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_files = list(DATA_DIR.glob(\"*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_corpus, max_word_count = None, -1\n",
    "for file in decade_files:\n",
    "\n",
    "    decade_name = file.name[-9:-4]\n",
    "    preprocessed_file_path = DATA_DIR / f\"preprocessed_{decade_name}.txt\"\n",
    "    with open(preprocessed_file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        word_count = len(\"\".join(text.split(\"\\n\")).split())\n",
    "        if word_count > max_word_count:\n",
    "            largest_corpus = decade_name\n",
    "            max_word_count = word_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1990s'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sardter/Desktop/work/Bilkent/ee486/Persian-Turkish-NLP/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp, json, optuna\n",
    "from gensim.models import FastText\n",
    "from evaluation import eval_loanword_coverage, eval_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-15 21:35:42,262] Using an existing study with name 'fasttext_tuning' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"vector_size\": trial.suggest_categorical(\"dim\", [100, 200, 300]),\n",
    "        \"window\":      trial.suggest_categorical(\"win\", [3, 5, 8]),\n",
    "        \"min_count\":   trial.suggest_categorical(\"mc\",  [2, 3, 5]),\n",
    "        \"sg\":          trial.suggest_categorical(\"sg\",  [0, 1]),\n",
    "        \"negative\":    trial.suggest_categorical(\"neg\", [5, 10, 15]),\n",
    "        \"epochs\":      trial.suggest_categorical(\"ep\",  [10, 20, 30]),\n",
    "        \"min_n\":       trial.suggest_categorical(\"minn\",[2, 3]),\n",
    "        \"max_n\":       trial.suggest_categorical(\"maxn\",[4, 6]),\n",
    "        \"sample\":      trial.suggest_categorical(\"samp\",[1e-3, 1e-4]),\n",
    "        \"workers\":     max(mp.cpu_count()-3, 2),\n",
    "        \"seed\":        42,\n",
    "    }\n",
    "\n",
    "    preprocessed_file_path = DATA_DIR / f\"preprocessed_{largest_corpus}.txt\"\n",
    "    try:\n",
    "        with open(preprocessed_file_path, 'r', encoding='utf-8') as f:\n",
    "            sentences = [line.strip().split() for line in f.readlines()]\n",
    "        logging.info(f\"Loaded {len(sentences)} sentences from preprocessed file.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Could not read preprocessed file {preprocessed_file_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    model = FastText(sentences, **params)       # sentences = one-decade list of tokens\n",
    "    loan_cov = eval_loanword_coverage(model)    # 0‒1\n",
    "    align_acc = eval_alignment(model)           # 0‒1\n",
    "    time_pen  = model.total_train_time / 3600   # hours\n",
    "\n",
    "    score = (loan_cov * align_acc) / (1 + 0.1 * time_pen)\n",
    "    trial.set_user_attr(\"params\", params)\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///ft_tuning.db\",\n",
    "    study_name=\"fasttext_tuning\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, n_trials=30, timeout=8*3600)\n",
    "best = study.best_trial.user_attrs[\"params\"]\n",
    "with open(\"best_ft_params.json\", \"w\") as f: json.dump(best, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decade_files = list(DATA_DIR.glob(\"*.txt\"))\n",
    "for text_file in sorted(decade_files): \n",
    "    train_decade_model(text_file)\n",
    "\n",
    "logging.info(\"All decades processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2Nn7KEQejYy"
   },
   "outputs": [],
   "source": [
    "test_model_path = MODEL_OUTPUT_DIR / \"fasttext_1940s.model\"\n",
    "if not test_model_path.exists():\n",
    "    logging.error(f\"Test model {test_model_path} not found. Run training first.\")\n",
    "\n",
    "logging.info(f\"\\n--- Loading and testing model: {test_model_path} ---\")\n",
    "loaded_model = FastText.load(str(test_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most similar word\n",
    "word = 'çene'\n",
    "try:\n",
    "    similar_words = loaded_model.wv.most_similar(word, topn=10)\n",
    "    print([t[0] for t in similar_words])\n",
    "except KeyError:\n",
    "    logging.info(f\"{word} is not in vocabulary of 1930s model (or below min_count).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vector for a word\n",
    "try:\n",
    "    word_vector = loaded_model.wv[\"cumhuriyet\"]\n",
    "    logging.info(f\"Vector for 'cumhuriyet': {word_vector[:5]}...\") # Print first 5 dims\n",
    "except KeyError:\n",
    "    logging.info(\"'cumhuriyet' not in vocabulary of 1930s model (or below min_count).\")\n",
    "\n",
    "logging.info(f\"Vector for OOV word '{word_vector}': {word_vector[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastText can also get vectors for OOV words if their n-grams are known\n",
    "oov_word = \"yepyenişeyler\" # A made-up word\n",
    "oov_vector = loaded_model.wv[oov_word]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
