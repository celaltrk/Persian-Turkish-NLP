{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-LpNwXd-ciSr",
    "outputId": "ca1c90ca-01a3-4320-8702-2e35cf78fdd2"
   },
   "outputs": [],
   "source": [
    "!pip install gensim tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "L2qo-5I-Yutg",
    "outputId": "b05e09fa-3bd5-42a8-98d8-411a134b9182"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from gensim.models import FastText\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "DATA_DIR = Path(\"./preprocessed\")\n",
    "MODEL_OUTPUT_DIR = Path(\"./embedding_models\")\n",
    "MODEL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# FastText Model Parameters\n",
    "VECTOR_SIZE = 100  # Dimensionality of the word vectors\n",
    "WINDOW_SIZE = 5    # Context window size\n",
    "MIN_WORD_COUNT = 5 # Minimum word frequency to consider\n",
    "SKIP_GRAM = 1      # 1 for Skip-gram, 0 for CBOW. Skip-gram is generally better.\n",
    "EPOCHS = 15        # Number of training iterations over the corpus\n",
    "MIN_N_CHAR_GRAM = 3 # Minimum length of char n-grams\n",
    "MAX_N_CHAR_GRAM = 6 # Maximum length of char n-grams\n",
    "NEGATIVE = 5 # SGNS\n",
    "\n",
    "NUM_WORKERS = os.cpu_count() if os.cpu_count() else 4 # Use available CPU cores\n",
    "NUM_WORKERS = NUM_WORKERS - 3 # prevent excessive load\n",
    "logging.info(f\"Number of workers is {NUM_WORKERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ivg6ZhMe0ZY"
   },
   "outputs": [],
   "source": [
    "def train_decade_model(text_file_path):\n",
    "    decade_name = text_file_path.name[-9:-4]  # 1930s, 1940s, etc\n",
    "    logging.info(f\"--- Processing decade: {decade_name} ---\")\n",
    "\n",
    "    preprocessed_file_path = DATA_DIR / f\"preprocessed_{decade_name}.txt\"\n",
    "    logging.info(f\"Loading preprocessed sentences from {preprocessed_file_path}...\")\n",
    "    try:\n",
    "        with open(preprocessed_file_path, 'r', encoding='utf-8') as f:\n",
    "            sentences = [line.strip().split() for line in f.readlines()]\n",
    "        logging.info(f\"Loaded {len(sentences)} sentences from preprocessed file.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Could not read preprocessed file {preprocessed_file_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Train the FastText model\n",
    "    logging.info(f\"Training FastText model for {decade_name}...\")\n",
    "    model = FastText(\n",
    "        sentences=sentences,\n",
    "        vector_size=VECTOR_SIZE,\n",
    "        window=WINDOW_SIZE,\n",
    "        min_count=MIN_WORD_COUNT,\n",
    "        sg=SKIP_GRAM,\n",
    "        negative=NEGATIVE,\n",
    "        epochs=EPOCHS,\n",
    "        min_n=MIN_N_CHAR_GRAM,\n",
    "        max_n=MAX_N_CHAR_GRAM,\n",
    "        workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    # Save the trained model\n",
    "    model_save_path = MODEL_OUTPUT_DIR / f\"fasttext_{decade_name}.model\"\n",
    "    try:\n",
    "        model.save(str(model_save_path))\n",
    "        logging.info(f\"Model for {decade_name} saved to {model_save_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Could not save model for {decade_name}: {e}\")\n",
    "\n",
    "    logging.info(f\"--- Finished processing for decade: {decade_name} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decade_files = list(DATA_DIR.glob(\"*1940s.txt\")) # adjust\n",
    "for text_file in sorted(decade_files): \n",
    "    train_decade_model(text_file)\n",
    "\n",
    "logging.info(\"All decades processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2Nn7KEQejYy"
   },
   "outputs": [],
   "source": [
    "test_model_path = MODEL_OUTPUT_DIR / \"fasttext_1930s.model\"\n",
    "if not test_model_path.exists():\n",
    "    logging.error(f\"Test model {test_model_path} not found. Run training first.\")\n",
    "\n",
    "logging.info(f\"\\n--- Loading and testing model: {test_model_path} ---\")\n",
    "loaded_model = FastText.load(str(test_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most similar word\n",
    "word = 'kanun'\n",
    "try:\n",
    "    similar_words = loaded_model.wv.most_similar(word, topn=10)\n",
    "    print([t[0] for t in similar_words])\n",
    "except KeyError:\n",
    "    logging.info(f\"{word} is not in vocabulary of 1930s model (or below min_count).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vector for a word\n",
    "try:\n",
    "    word_vector = loaded_model.wv[\"cumhuriyet\"]\n",
    "    logging.info(f\"Vector for 'cumhuriyet': {word_vector[:5]}...\") # Print first 5 dims\n",
    "except KeyError:\n",
    "    logging.info(\"'cumhuriyet' not in vocabulary of 1930s model (or below min_count).\")\n",
    "\n",
    "logging.info(f\"Vector for OOV word '{word_vector}': {word_vector[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastText can also get vectors for OOV words if their n-grams are known\n",
    "oov_word = \"yepyeni≈üeyler\" # A made-up word\n",
    "oov_vector = loaded_model.wv[oov_word]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
